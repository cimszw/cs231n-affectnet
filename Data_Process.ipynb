{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a data processing script. Converts the image files into 3D Tensors and expression value as an int between 0 and 10. Can feed into pytorch dataloader for shuffling and creating batches. Using manually annotated list of folders for processing on small set of data. Can remove the requirement inFolder when getting all data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reads in the csv and splits it to get list of folders from Pandas dataframe. This is needed if we are only making a small dataset of specific folders. Ignore if using full dataset listed in excel document. Because we are using manually annotated data only, this is a necessary step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sheet = pd.read_csv('training.csv')\n",
    "training_sheet_split = pd.DataFrame(training_sheet.subDirectory_filePath.str.split(\"/\").tolist(),columns = ['folder','subpath'])\n",
    "folders = list(map(int,training_sheet_split.folder))\n",
    "folder_list = [1,10,100, 102, 103] + list(range(1000,1030))\n",
    "inFolder = np.isin(folders, folder_list)\n",
    "#print(np.where(inFolder)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataset class that reads in csv, transforms, and included folders of images. The length function gives an accurate size, and the getitem allows retrieval of 3D tensor of image plus expression as an int. This is returned as a tuple when indexing through the dataset object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    \"\"\"Face dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None, inFolder=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.training_sheet = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        if inFolder.any() == None:\n",
    "            self.inFolder = np.full((len(self.training_sheet),), True)\n",
    "        \n",
    "        self.loc_list = np.where(inFolder)[0]\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return  np.sum(self.inFolder*1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.loc_list[idx] \n",
    "        emotion = self.training_sheet.iloc[idx,6]\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.training_sheet.iloc[idx, 0])\n",
    "        \n",
    "        image = Image.open(img_name)\n",
    "        sample = image\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the dataset with resizing, random cropping, and transforming to a tensor. Info can be found here. \n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_dataset = FaceDataset(csv_file='training.csv',\n",
    "                                    root_dir='Manually_Annotated_Images', transform=transforms.Compose([\n",
    "                                        transforms.Resize(256), transforms.RandomCrop(size=128), transforms.ToTensor()\n",
    "                                    ]), inFolder = inFolder)\n",
    "                                  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128, 128])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "im, y = face_dataset[0]\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(transformed_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
