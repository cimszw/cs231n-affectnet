{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was an attempt to build on a starter ResNext model given by the AffectNet team.  However, we ran into implementation issues around batch size, cropping, general weak model performance, and many errors in completing the model runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/shared/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import h5py\n",
    "import tflearn\n",
    "\n",
    "TRAIN_H5 = 'train.h5'\n",
    "VAL_H5 = 'val.h5'\n",
    "\n",
    "#BATCH_SIZE = 256\n",
    "#CROP_SIZE = 49 # too small, weak model (validation accuracy ~35%)\n",
    "\n",
    "BATCH_SIZE = 4 # too large, get Output elements too large for GPU kernel\n",
    "CROP_SIZE = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_h5f = h5py.File(TRAIN_H5, 'r')\n",
    "trainX = train_h5f['X']\n",
    "trainY = train_h5f['Y']\n",
    "\n",
    "val_h5f = h5py.File(VAL_H5, 'r')\n",
    "valX = val_h5f['X']\n",
    "valY = val_h5f['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time data preprocessing\n",
    "img_prep = tflearn.ImagePreprocessing()\n",
    "MEAN = [0.53990436 , 0.4405486  , 0.39328504] # already calculated, expedite processing\n",
    "img_prep.add_featurewise_zero_center(per_channel=True, mean=MEAN)\n",
    "\n",
    "\n",
    "# Real-time data augmentation\n",
    "img_aug = tflearn.ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_crop([CROP_SIZE, CROP_SIZE], padding=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/maxschorer/.local/lib/python3.6/site-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    }
   ],
   "source": [
    "n = 5 # 32 layers\n",
    "# Building Residual Network\n",
    "net = tflearn.input_data(shape=[None, CROP_SIZE, CROP_SIZE, 3],\n",
    "                         data_preprocessing=img_prep,\n",
    "                         data_augmentation=img_aug)\n",
    "net = tflearn.conv_2d(net, 16, 3, regularizer='L2', weight_decay=0.0001)\n",
    "net = tflearn.resnext_block(net, n, 16, 32)\n",
    "net = tflearn.resnext_block(net, 1, 32, 32, downsample=True)\n",
    "net = tflearn.resnext_block(net, n-1, 32, 32)\n",
    "net = tflearn.resnext_block(net, 1, 64, 32, downsample=True)\n",
    "net = tflearn.resnext_block(net, n-1, 64, 32)\n",
    "net = tflearn.batch_normalization(net)\n",
    "net = tflearn.activation(net, 'relu')\n",
    "net = tflearn.global_avg_pool(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/maxschorer/.local/lib/python3.6/site-packages/tflearn/objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "net = tflearn.fully_connected(net, 11, activation='softmax')\n",
    "opt = tflearn.Momentum(0.1, lr_decay=0.1, decay_step=32000, staircase=True)\n",
    "net = tflearn.regression(net, optimizer=opt,\n",
    "                         loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tflearn.DNN(net, checkpoint_path='model_resnet_affectnet_full',\n",
    "                    max_checkpoints=10, tensorboard_verbose=0,\n",
    "                    clip_gradients=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m1.74110\u001b[0m\u001b[0m | time: 430.457s\n",
      "\u001b[2K\r",
      "| Momentum | epoch: 003 | loss: 1.74110 - acc: 0.2735 -- iter: 01108/96011\n"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, trainY, n_epoch=1, validation_set=(valX, valY),\n",
    "          snapshot_epoch=False, snapshot_step=500,\n",
    "          show_metric=True, batch_size=BATCH_SIZE, shuffle=True,\n",
    "          run_id='resnet_affectnet_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the above, at the current rate, training one epoch would have taken an estimated 70 hours."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
