{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "import pandas as pd\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "from tflearn.data_utils import build_hdf5_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = 'training.csv'\n",
    "#VAL = 'validation.csv'\n",
    "TRAIN_TRIM = 'training_trim.csv'\n",
    "\n",
    "FULL_COLS = ['file_path','face_x','face_y','face_width','face_height','facial_landmarks','expression','valence','arousal']\n",
    "TRIM_COLS = ['file_path', 'face_x', 'face_y', 'face_width', 'face_height', 'expression']\n",
    "\n",
    "training = pd.read_csv(os.environ['HOME'] + '/' + TRAIN)\n",
    "#validation = pd.read_csv(VAL, names=FULL_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TRIM = 'training_trim.csv'\n",
    "\n",
    "FULL_COLS = ['file_path','face_x','face_y','face_width','face_height','facial_landmarks','expression','valence','arousal']\n",
    "TRIM_COLS = ['file_path', 'face_x', 'face_y', 'face_width', 'face_height', 'expression']\n",
    "training.columns = FULL_COLS\n",
    "training = training[TRIM_COLS]\n",
    "training.to_csv(TRAIN_TRIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = 'training_trim.csv'\n",
    "DATASET_FILE = 'train_dataset.txt'\n",
    "TRAIN_H5 = 'train.h5'\n",
    "IMG_SIZE = 256\n",
    "DATA_DIR = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1000 images\n",
      "Processed 2000 images\n",
      "Processed 3000 images\n",
      "Processed 4000 images\n",
      "Processed 5000 images\n",
      "Processed 6000 images\n",
      "Processed 7000 images\n",
      "Processed 8000 images\n",
      "Processed 9000 images\n",
      "Processed 10000 images\n",
      "Processed 11000 images\n",
      "Processed 12000 images\n",
      "Processed 13000 images\n",
      "Processed 14000 images\n",
      "Processed 15000 images\n",
      "Processed 16000 images\n",
      "Processed 17000 images\n",
      "Processed 18000 images\n",
      "Processed 19000 images\n",
      "Processed 20000 images\n",
      "Processed 21000 images\n",
      "Processed 22000 images\n",
      "Processed 23000 images\n",
      "Processed 24000 images\n",
      "Processed 25000 images\n",
      "Processed 26000 images\n",
      "Processed 27000 images\n",
      "Processed 28000 images\n",
      "Processed 29000 images\n",
      "Processed 30000 images\n",
      "Processed 31000 images\n",
      "Processed 32000 images\n",
      "Processed 33000 images\n",
      "Processed 34000 images\n",
      "Processed 35000 images\n",
      "Processed 36000 images\n",
      "Processed 37000 images\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(TRAIN_FILE)\n",
    "f = open(DATASET_FILE, 'w')\n",
    "\n",
    "for idx, row in training.iterrows():\n",
    "    file_path = os.environ['HOME'] + '/' + row['file_path'].split('/')[1]\n",
    "    if not os.path.isfile(file_path): continue\n",
    "    # crop image\n",
    "    # write logic to toss out poorly formatted images\n",
    "    line_string = '{} {}\\n'.format(file_path, row['expression'])\n",
    "    f.write(line_string)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = 'train_dataset_trim.txt'\n",
    "build_hdf5_image_dataset(dataset_file, image_shape=(IMG_SIZE, IMG_SIZE), mode='file', \n",
    "                         output_path=TRAIN_H5, normalize=True, categorical_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File(TRAIN_H5, 'r')\n",
    "X = h5f['X']\n",
    "Y = h5f['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual blocks\n",
    "# 32 layers: n=5, 56 layers: n=9, 110 layers: n=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-time data preprocessing\n",
    "img_prep = tflearn.ImagePreprocessing()\n",
    "img_prep.add_featurewise_zero_center(per_channel=True)\n",
    "\n",
    "\n",
    "# Real-time data augmentation\n",
    "img_aug = tflearn.ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_crop([32, 32], padding=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "tf.reset_default_graph()\n",
    "# Building Residual Network\n",
    "net = tflearn.input_data(shape=[None, 32, 32, 3],\n",
    "                         data_preprocessing=img_prep,\n",
    "                         data_augmentation=img_aug)\n",
    "net = tflearn.conv_2d(net, 16, 3, regularizer='L2', weight_decay=0.0001)\n",
    "net = tflearn.resnext_block(net, n, 16, 32)\n",
    "net = tflearn.resnext_block(net, 1, 32, 32, downsample=True)\n",
    "net = tflearn.resnext_block(net, n-1, 32, 32)\n",
    "net = tflearn.resnext_block(net, 1, 64, 32, downsample=True)\n",
    "net = tflearn.resnext_block(net, n-1, 64, 32)\n",
    "net = tflearn.batch_normalization(net)\n",
    "net = tflearn.activation(net, 'relu')\n",
    "net = tflearn.global_avg_pool(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "net = tflearn.fully_connected(net, 11, activation='softmax')\n",
    "opt = tflearn.Momentum(0.1, lr_decay=0.1, decay_step=32000, staircase=True)\n",
    "net = tflearn.regression(net, optimizer=opt,\n",
    "                         loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tflearn.DNN(net, checkpoint_path='model_resnet_affectnet',\n",
    "                    max_checkpoints=10, tensorboard_verbose=0,\n",
    "                    clip_gradients=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, Y, n_epoch=1, validation_set=(X, Y),\n",
    "          snapshot_epoch=False, snapshot_step=500,\n",
    "          show_metric=True, batch_size=128, shuffle=True,\n",
    "          run_id='resnet_affectnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
